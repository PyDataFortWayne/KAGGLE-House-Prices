{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns # heatmaps yay\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from scipy.stats import skew\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import boxcox\n",
    "\n",
    "from scipy.special import inv_boxcox\n",
    "\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmbda_opts = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_high_missing_features(df):\n",
    "    tot_rec = len(df.index)\n",
    "    for col in df.columns.values:\n",
    "        if df[col].isnull().sum() / tot_rec > 0.15:\n",
    "            del df[col]\n",
    "\n",
    "def impute_missing_data(df):\n",
    "    fill_with = {'None': ['PoolQC', 'MiscFeature', 'Alley', 'Fence',\n",
    "                 'FireplaceQu', 'GarageType', 'GarageFinish',\n",
    "                 'GarageQual', 'BsmtQual', 'BsmtCond', 'BsmtExposure',\n",
    "                 'BsmtFinType1', 'BsmtFinType2', 'MasVnrType', 'MSSubClass'],\n",
    "               0: ['GarageYrBlt', 'GarageArea', 'GarageCars',\n",
    "                   'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', \n",
    "                   'TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath',\n",
    "                   'MasVnrArea'\n",
    "                  ]}\n",
    "    for fw in fill_with:\n",
    "        for f in fill_with[fw]:\n",
    "            df[f] = df[f].fillna(fw)\n",
    "    \n",
    "    \n",
    "    df[\"Functional\"] = df[\"Functional\"].fillna(\"Typ\")\n",
    "    \n",
    "    \n",
    "    mode_list = ['SaleType', 'Exterior2nd', 'Exterior1st', 'KitchenQual', \n",
    "                 'Electrical', 'MSZoning']\n",
    "    for f in mode_list:\n",
    "        df[f] = df[f].fillna(df[f].mode()[0])\n",
    "    \n",
    "    \n",
    "    df[\"LotFrontage\"] = df.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(lambda x: x.fillna(x.median()))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def calculate_nulls(df):\n",
    "    df_nulls = df.copy().isnull().sum()\n",
    "    df_nulls = df_nulls.to_frame().rename(columns={0:'num_nulls'})\n",
    "    df_nulls['total_records'] = len(df.index)\n",
    "    df_nulls['pct_null'] = df_nulls['num_nulls'] / df_nulls['total_records'] * 100\n",
    "    df_nulls = df_nulls[df_nulls['num_nulls'] > 0].sort_values(by='pct_null', ascending=False)\n",
    "    return df_nulls\n",
    "\n",
    "def process_df(df, is_test=False):\n",
    "    df.set_index('Id')\n",
    "\n",
    "    df = impute_missing_data(df)\n",
    "    \n",
    "    df = df.drop(['Utilities'], axis=1)\n",
    "\n",
    "    # Convert to strings as they're categories:\n",
    "    str_cols = ['MSSubClass', 'OverallCond', 'MoSold', 'YrSold', 'YearRemodAdd', 'YearBuilt', 'GarageYrBlt']\n",
    "    for f in str_cols:\n",
    "        df[f] = df[f].astype(str)\n",
    "\n",
    "    ohe_cols = df.dtypes[df.dtypes == \"object\"].index\n",
    "    df_dummies = pd.get_dummies(df[ohe_cols])\n",
    "    df = df.drop(ohe_cols, axis='columns')\n",
    "    df = pd.concat([df, df_dummies], sort=False, axis='columns')\n",
    "\n",
    "    # Use a label encoder for the categorical fields\n",
    "    le_cols = ['FireplaceQu', 'BsmtQual', 'BsmtCond', 'GarageQual', 'GarageCond', \n",
    "           'ExterQual', 'ExterCond','HeatingQC', 'PoolQC', 'KitchenQual', 'BsmtFinType1', \n",
    "           'BsmtFinType2', 'Functional', 'Fence', 'BsmtExposure', 'GarageFinish', 'LandSlope',\n",
    "           'LotShape', 'PavedDrive', 'Street', 'Alley', 'CentralAir', 'MSSubClass', 'OverallCond', \n",
    "           'MoSold', 'YrSold', 'YearRemodAdd', 'YearBuilt', 'GarageYrBlt']\n",
    "    for c in le_cols:\n",
    "        if c in df.columns.values:\n",
    "            le = LabelEncoder() \n",
    "            le.fit(list(df[c].values)) \n",
    "            df[c] = le.transform(list(df[c].values))\n",
    "        \n",
    "    numeric_feats = df.dtypes[df.dtypes != \"object\"].index.values        \n",
    "    df = df.loc[:, numeric_feats]\n",
    "        \n",
    "    # Sale Price is in our training data, but not testing data\n",
    "    shift = 1.0\n",
    "    if 'SalePrice' in df.columns.values:\n",
    "        filter = (df['GrLivArea'] > 4000) & (df['SalePrice'] < 200000)\n",
    "        df = df.loc[~filter, :]\n",
    "\n",
    "        # Check the skew of all numerical features\n",
    "        skewed_feats = df[numeric_feats[1:]].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\n",
    "        skewness = pd.DataFrame({'Skew' :skewed_feats})\n",
    "        \n",
    "        for f in skewness[abs(skewness) > 0.75].index:\n",
    "            if f not in le_cols and '_' not in f: #ignore label encoded fields and OHE columns\n",
    "                df[f], lmbda_opts[f] = boxcox(df[f] + shift)\n",
    "\n",
    "    else:  # Test data\n",
    "        for f in lmbda_opts:\n",
    "            if f in df.columns:\n",
    "                df[f] = boxcox(df[f] + shift, lmbda=lmbda_opts[f])\n",
    "            elif f != 'SalePrice':\n",
    "                df[f] = 0\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title = 'Confusion Matrix',\n",
    "                          cmap = plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print('Normalized Confusion Matrix')\n",
    "    else:\n",
    "        print('Confusion Matrix Without Normalization')\n",
    "    print(cm)\n",
    "    \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    \n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    for i,j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i,j], fmt),\n",
    "                horizontalalignment=\"center\",\n",
    "                color=\"white\" if cm[i,j] > thresh else \"black\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def encode_text_index(df, name):\n",
    "    le = LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc, confusion_matrix\n",
    "\n",
    "def show_results(clf, X, y):\n",
    "    acc_score = clf.score(X, y)\n",
    "    print('Accuracy: {}'.format(acc_score*100))\n",
    "    \n",
    "    y_pred = clf.predict(X)\n",
    "    cm_matrix = confusion_matrix(y, y_pred)\n",
    "    np.set_printoptions(precision=2)\n",
    "    \n",
    "    Class = encode_text_index(pd.DataFrame(y), y.columns[0])\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    plot_confusion_matrix(cm_matrix, classes=Class, normalize=True)\n",
    "    plt.show()\n",
    "    \n",
    "    y_pred = clf.predict_proba(X)\n",
    "    fpr, tpr, thresholds = roc_curve(y, y_pred[:, 1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    lw = 2\n",
    "    \n",
    "    plt.plot(fpr, tpr, color='red', lw=lw, label='ROC Curve (area = {:%0.2f})'.format(roc_auc))\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC)')\n",
    "    plt.legend(loc='lower right', frameon=False)\n",
    "    \n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_skm(model, X_train, y_train, X_test, y_test, X_pred, model_params={}):\n",
    "    cn = type(model).__name__\n",
    "    print(f\"Model: {cn}\")\n",
    "    model.fit(X_train, y_train, **model_params)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_test_pred)\n",
    "    model_score = model.score(X_train, y_train)\n",
    "    print(f\"Root Mean Squared Error: {math.sqrt(mse)} - Score: {model_score}\")\n",
    "    \n",
    "    y_pred = model.predict(X_pred)\n",
    "    \n",
    "    df_sub = pd.DataFrame(y_pred, index=X_pred['Id'], columns=['SalePrice'])\n",
    "    df_sub['SalePrice'] = inv_boxcox(df_sub['SalePrice'], lmbda_opts['SalePrice'])\n",
    "    df_sub.to_csv(os.path.join('submissions', f\"{cn}.{datetime.now():%Y%M%d_%H%m%s}.csv\"))\n",
    "    return y_pred\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the train csv file to take a look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join('data','train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 1000\n",
    "pd.options.display.max_rows = 1000\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many records are we dealing with?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determine which features are important"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much of each feature is null?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_nulls(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "sns.heatmap(df.isnull(), cbar=False, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another interesting note is that the GarageX type features all have the same amount of null values. This is likely because they're a part of the same records. We can verify this to see how many records have all those features set to null."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let's take a look at the correlations between each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize = (30,20))\n",
    "sns.heatmap(df.corr(), cmap=\"YlGnBu\", annot=True);\n",
    "plt.title(\"Heatmap of Feature Correlation\", fontsize = 30);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the correlation heat map we can quickly identify features which are highly related to other features. For example 1stFlSF and TotalBsmntSF are highly correlated which makes sense because generally speaking most basements are full basements (the basement is wearing the first floor like a hat). The same goes for 1stFlSF and 2ndFlSF (This house is a mad hatter).\n",
    "\n",
    "Another instance is GarageCars and GarageArea. This makes sense because you need more space to store more cars. This is the same rationale for TotRmsAbvGrd (Total rooms above ground) and GrLivArea (ground floor living area).\n",
    "\n",
    "YearBuilt and GarageYrBlt also appear to be highly correlated. This makes sense because typically the house and the garage are built at the same time.\n",
    "\n",
    "Let's take some time to graph some of these relationships and see what comes up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize = (20,12))\n",
    "sns.scatterplot(x=df['GrLivArea'], y= df['SalePrice']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter = (df['GrLivArea'] > 4000) & (df['SalePrice'] < 200000)\n",
    "df[filter][['GrLivArea', 'SalePrice']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the graph there are four possible outliers, two with a sale price over $700,000 and two with over 4500 sq. ft. but a much lower price. If we follow the trend of the graph the higher two outliers seem to fit the pattern and we can likely keep these two in however we should probably remove the other two outliers. As this is unique to the training dataset we'll do that below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df['Electrical'].notna()\n",
    "df = df.loc[(mask), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(np.log(df['GrLivArea']), np.log(df['SalePrice']));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Box-Cox test quickly and easily tells us if  we need to perform a transform on our data or not by telling us a lambda value:\n",
    "\n",
    "* -1. is a reciprocal\n",
    "* -.5 is a recriprocal square root\n",
    "* 0.0 is a log transformation\n",
    "* .5 is a square root transform and\n",
    "* 1.0 is no transform.\n",
    "\n",
    "It's important that our data be transformed into a normal distribution as most regression models require the data to be normally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc_list = ['LotArea', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'GrLivArea', 'GarageArea', 'SalePrice']\n",
    "\n",
    "for c in bc_list:\n",
    "    xt, maxlog = boxcox(df[c] + 1)\n",
    "    fig = plt.figure()\n",
    "    sns.scatterplot(df[c], xt, alpha=0.5);\n",
    "\n",
    "    print(\"{} lambda = {:g}\".format(c, maxlog))\n",
    "    \n",
    "    #plt.show_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the Box-Cox test we ran on the columns from our dataset, we need to perform the following transformations in our `process_df` function:\n",
    "\n",
    "- Log\n",
    "  - LotArea\n",
    "  - 1stFlrSF\n",
    "  - 2ndFlrSF\n",
    "  - SalePrice\n",
    "  - GrLivArea\n",
    "\n",
    "- Square root\n",
    "  - TotalBsmtSF\n",
    "  - GarageArea\n",
    "  \n",
    "\n",
    "Alternatively we can just use the transformed data (`xt` above) returned by the `boxcox` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join('data','train.csv'))\n",
    "df = process_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = df.pop('SalePrice')\n",
    "X = df\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=8675309)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['LotArea', \n",
    "            '1stFlrSF',\n",
    "            '2ndFlrSF',\n",
    "            'GrLivArea',\n",
    "            'TotalBsmtSF',\n",
    "            'GarageArea',\n",
    "            'YearBuilt',\n",
    "            'FullBath',\n",
    "            'BedroomAbvGr',\n",
    "            'OverallQual']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'objective': 'reg:linear', 'max_depth': 100, 'lambda': 0.5, 'alpha': 0.5, 'eta': 1} #, 'eval_metric': 'auc'\n",
    "evallist = [(dtrain, 'train'), (dtest, 'eval')]\n",
    "num_round = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst = xgb.train(param, dtrain, num_round, evallist, early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.plot_importance(bst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.plot_tree(bst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtest = xgb.DMatrix(X_test)\n",
    "ypred = bst.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_test, ypred)\n",
    "print(f\"Root Mean Squared Error: {math.sqrt(mse)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst.best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = pd.read_csv(os.path.join('data','test.csv'))\n",
    "df_pred = process_df(df_pred, is_test=True)\n",
    "\n",
    "c_in_train = [c for c in df_pred.columns.values if c in X_train]\n",
    "c_nin_pred = [c for c in X_train.columns.values if c not in df_pred]\n",
    "\n",
    "df_pred = df_pred.loc[:, c_in_train]\n",
    "\n",
    "for c in c_nin_pred:\n",
    "    df_pred[c] = 0\n",
    "    \n",
    "df_pred = df_pred[X_train.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpred = xgb.DMatrix(df_pred)\n",
    "ypred = bst.predict(dpred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = pd.DataFrame(ypred, index=df_pred['Id'], columns=['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub['SalePrice'] = inv_boxcox(df_sub['SalePrice'], lmbda_opts['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "df_sub.to_csv(os.path.join('submissions', f'XGBoost_{now:%Y%m%d%H%M%S}.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit Learn Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import PassiveAggressiveRegressor\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "lr = LinearRegression()\n",
    "en = ElasticNet()\n",
    "\n",
    "rfr = RandomForestRegressor(n_estimators=100)\n",
    "gbr = GradientBoostingRegressor()\n",
    "\n",
    "dtr = DecisionTreeRegressor()\n",
    "\n",
    "\n",
    "\n",
    "models = [lr, en, rfr, gbr, dtr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_nulls(df_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred.describe().loc['max'].T.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_nulls(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    try:\n",
    "        run_skm(model, X_train, y_train, X_test, y_test, df_pred)\n",
    "    except Exception as e:\n",
    "        print(f'Error with model {model} - {e}')\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
